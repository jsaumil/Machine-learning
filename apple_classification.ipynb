{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWR92HgnSLrd"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KkBpFuvV-23"
      },
      "source": [
        "/content/train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7-C_RksYJsU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-iTChAiTGKd",
        "outputId": "bb0745b6-1c10-48a8-a866-6fc76e434baa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Failed to load _annotations.csv\n",
            "Train set shape: (385, 128, 128)\n",
            "Test set shape: (82, 128, 128)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Define the folder containing images\n",
        "train_folder = '/content/drive/My Drive/Colab Notebooks/train'\n",
        "test_folder = '/content/drive/My Drive/Colab Notebooks/test'\n",
        "valid_folder = '/content/drive/My Drive/Colab Notebooks/valid'\n",
        "\n",
        "# Initialize lists to store images and labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Function to preprocess images\n",
        "def preprocess_images(folder):\n",
        "    # Clear the images and labels before appending new data\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "\n",
        "        # Read the image using OpenCV\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            # Convert BGR to RGB for display\n",
        "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "            # Resize image (optional, resize to a common size)\n",
        "            img_resized = cv2.resize(img_gray, (128, 128))\n",
        "\n",
        "            # Append image and label\n",
        "            images.append(img_resized)\n",
        "            labels.append('apple')  # Assuming all images in this folder are 'apple'\n",
        "        else:\n",
        "            print(f\"Failed to load {filename}\")\n",
        "\n",
        "    # Convert lists to NumPy arrays\n",
        "    images = np.array(images)\n",
        "\n",
        "    # # Convert labels from strings to integers\n",
        "    # label_encoder = LabelEncoder()\n",
        "    # labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "# Preprocess train, validation, and test images\n",
        "X_train, y_train = preprocess_images(train_folder)\n",
        "#X_val, y_val = preprocess_images(valid_folder)\n",
        "X_test, y_test = preprocess_images(test_folder)\n",
        "\n",
        "# Optional: Check the shape of the datasets\n",
        "print(f\"Train set shape: {X_train.shape}\")\n",
        "#print(f\"Validation set shape: {X_val.shape}\")#\n",
        "print(f\"Test set shape: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CtAlFsqdSCE",
        "outputId": "c34c7f9a-5dbd-4787-f7dc-5a7802b77081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "385"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvRYSKjLWbuW",
        "outputId": "6f91f616-feb4-47e0-9457-7ee9eb244e35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "img_size=(128,128)\n",
        "model = Sequential([\n",
        "        # Convolutional layers\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(128,128, 1)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        # Flatten and dense layers\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='softmax')  # Binary classification output\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAlVCEwXYx-L"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Define the folder containing images\n",
        "train_folder = '/content/drive/My Drive/Colab Notebooks/train'\n",
        "test_folder = '/content/drive/My Drive/Colab Notebooks/test'\n",
        "valid_folder = '/content/drive/My Drive/Colab Notebooks/valid'\n",
        "\n",
        "\n",
        "# Initialize lists to store images and labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Function to preprocess images\n",
        "def preprocess_images(folder,label):\n",
        "\n",
        "    valid_extensions = ('.jpg', '.jpeg', '.png')\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for filename in os.listdir(folder):\n",
        "        if filename.lower().endswith(valid_extensions):\n",
        "            img_path = os.path.join(folder, filename)\n",
        "\n",
        "            try:\n",
        "\n",
        "\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "\n",
        "                    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
        "                    img_edges = cv2.Canny(img_gray,threshold1=100,threshold2=200)\n",
        "\n",
        "                    img_resized = cv2.resize(img_edges, (128, 128))\n",
        "\n",
        "\n",
        "                    images.append(img_resized)\n",
        "                    labels.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading {img_path}: {e}\")\n",
        "\n",
        "        # Convert lists to NumPy arrays\n",
        "    images = np.array(images)\n",
        "\n",
        "        # # Convert labels from strings to integers\n",
        "        # label_encoder = LabelEncoder()\n",
        "        # labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "# Preprocess train, validation, and test images\n",
        "X_mango, y_mango = preprocess_images(train_mango,label=0)\n",
        "X_apple, y_apple = preprocess_images(train_apple,label=1)\n",
        "\n",
        "X_mango_test, y_mango_test = preprocess_images(test_mango,label=0)\n",
        "X_apple_test, y_apple_test = preprocess_images(test_apple,label=1)\n",
        "\n",
        "#X_mango_val, y_mango_val = preprocess_images(valid_mango,label=0)\n",
        "#X_apple_val, y_apple_val = preprocess_images(valid_apple,label=1)\n",
        "\n",
        "#X_val, y_val = preprocess_images(valid_folder)\n",
        "#X_test, y_test = preprocess_images(test_folder)\n",
        "# Ensure both arrays are numpy arrays\n",
        "X_apple = np.array(X_apple)\n",
        "X_mango = np.array(X_mango)\n",
        "\n",
        "X_apple_test = np.array(X_apple_test)\n",
        "X_mango_test = np.array(X_mango_test)\n",
        "\n",
        "#X_apple_val = np.array(X_apple_val)\n",
        "#X_mango_val = np.array(X_mango_val)\n",
        "\n",
        "# Combine along the first axis\n",
        "X_train = np.concatenate([X_apple, X_mango], axis=0)\n",
        "X_test = np.concatenate([X_apple_test, X_mango_test], axis=0)\n",
        "#X_val = np.concatenate([X_apple_val, X_mango_val], axis=0)\n",
        "\n",
        "y_apple = np.array(y_apple)\n",
        "y_mango = np.array(y_mango)\n",
        "\n",
        "y_apple_test = np.array(y_apple_test)\n",
        "y_mango_test = np.array(y_mango_test)\n",
        "\n",
        "#y_apple_val = np.array(y_apple_val)\n",
        "#y_mango_val = np.array(y_apple_val)\n",
        "\n",
        "# Combine labels\n",
        "y_train = np.concatenate([y_apple, y_mango], axis=0)\n",
        "y_test = np.concatenate([y_apple_test, y_mango_test], axis=0)\n",
        "#y_val = np.concatenate([y_apple_val, y_mango_val], axis=0)\n",
        "\n",
        "print(\"x_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "\n",
        "print(\"x_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "# print(\"x_valid shape:\", X_val.shape)\n",
        "# print(\"y_valid shape:\", y_val.shape)\n",
        "\n",
        "# Optional: Check the shape of the datasets\n",
        "print(f\"Train set shape: {X_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "# print(f\"Valid set shape: {X_val.shape}\")\n",
        "\n",
        "print(f\"Train set shape: {y_train.shape}\")\n",
        "print(f\"Test set shape: {y_test.shape}\")\n",
        "# print(f\"Valid set shape: {y_val.shape}\")"
      ],
      "metadata": {
        "id": "vKMmk18SWhs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = \"F:\\\\python\\\\deep learning\\\\riesling.v1i.folder\\\\test\"\n",
        "x,y=preprocess_images(test,label=0)\n",
        "\n",
        "x=np.array(x)\n",
        "y=np.array(y)"
      ],
      "metadata": {
        "id": "iO4HB4JdWkan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#img_size=(128,128)\n",
        "model = Sequential([\n",
        "        # Convolutional layers\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(128,128, 1)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        # Flatten and dense layers\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid'),\n",
        "        # Binary classification output\n",
        "    ])"
      ],
      "metadata": {
        "id": "guRRb_Fqy2IG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "41JLDRl2y_7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_apple, y_apple,\n",
        "    validation_split=0.1,\n",
        "    epochs=50,\n",
        "    batch_size=20\n",
        ")"
      ],
      "metadata": {
        "id": "bDO8OA6TzA9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image"
      ],
      "metadata": {
        "id": "r-4lBPbP2XxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(img_path, target_size=(150, 150)):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    img_array = img_array / 255.0  # Normalize to [0, 1]\n",
        "    return img_array\n",
        "\n"
      ],
      "metadata": {
        "id": "7SlyScWN2cI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_dir = r '/content/drive/My Drive/Colab Notebooks/Appledata_set/train'\n",
        "validation_dir = r '/content/drive/My Drive/Colab Notebooks/Appledata_set/valid'\n",
        "\n",
        "\n",
        "# Image Data Generator for Preprocessing\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',  # Set to 'binary' if it's a binary classification problem\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',  # Set to 'binary' if it's a binary classification problem\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Model Definition\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')  # Single output for binary classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "epochs = 10\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator\n",
        ")\n",
        "\n",
        "# Save the model after training\n",
        "model.save('apple_classifier_model.h5')\n",
        "\n",
        "# Prediction function\n",
        "def predict_image(img_path, model):\n",
        "    img_array = preprocess_image(img_path)\n",
        "    prediction = model.predict(img_array)\n",
        "    return 'Apple' if prediction[0] > 0.5 else 'Not Apple'\n",
        "\n",
        "# Load the model for prediction\n",
        "loaded_model = tf.keras.models.load_model('apple_classifier_model.h5')\n",
        "\n",
        "# Example prediction\n",
        "img_path = r'F:\\mobile-cover.jpg'  # Ensure this path is correct and points to an actual image file\n",
        "result = predict_image(img_path, loaded_model)\n",
        "print(f'The image is classified as: {result}')\n"
      ],
      "metadata": {
        "id": "ORIsz8dl2jQv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}